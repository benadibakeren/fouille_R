---
title: "<FONT color='#0066CC'><FONT size = 4 ><DIV align= center> AP-4209 ESIEE-Paris: 2025 - 2026 </DIV></FONT></FONT>"
output:
  html_document:
    highlight: textmate
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
---

<style type="text/css">
body, td {font-size: 15px;}
code.r{font-size: 12px;}
pre { font-size: 12px;}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"} 
Fouille de données\

PROJET 3 : CLASSIFICATION BAYÉSIENNE ET ANALYSE FACTORIELLE DISCRIMINANTE

-- Classification des Thèses de Doctorat Françaises -- 
:::

</FONT></FONT>

<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"} 
Auteurs : Meliana ZERROUG, Keren BENADIBA-- ESIEE Paris 
:::

</FONT></FONT>

<hr style="border: 1px solid gray">

</hr>

<DIV align = justify>

### <FONT color='#0066CC'><FONT size = 4> 1. Introduction et Objectifs </FONT></FONT>

Dans ce projet, nous allons nous intéresser à la classification de thèses de doctorat françaises à partir de leurs résumés.
Le jeu de données utilisé provient de Kaggle.
Nous commencerons par charger les données contenant les résumés des thèses. Ensuite, le texte est nettoyé en supprimant les mots inutiles (stopwords), la ponctuation, et en appliquant un stemming ou une lemmatisation. Après ce nettoyage, le texte est transformé en données numériques grâce à des méthodes de vectorisation comme TF-IDF. Puis, nous extrayons les caractéristiques les plus importantes et nous réduisons la dimension des données en utilisant l’analyse factorielle discriminante (AFD). Enfin, un classifieur bayésien naïf est entraîné à partir des données obtenues, puis évalué à l’aide de la validation croisée et de différentes mesures de performance.

</DIV>

<hr style="border: 1px solid gray">

</hr>

<DIV align = justify>

### <FONT color='#0066CC'><FONT size = 4> 2. Méthodologie </FONT></FONT>

#### <FONT color='#0066CC'><FONT size = 3> 2.1 Chargement des données </FONT></FONT>

Nous utilisons donc le jeu de données des thèses françaises. Nous allons donc d'abord charger les bibliothèques nécessaires. 

*  **Installation des packages nécessaires :**  

```{r}

# Définir un miroir CRAN
options(repos = c(CRAN = "https://cloud.r-project.org/"))

if(!require("dplyr")) install.packages("dplyr")
if(!require("kableExtra")) install.packages("kableExtra")
if(!require("tm")) install.packages("tm")
if(!require("MASS")) install.packages("MASS") 
if(!require("e1071")) install.packages("e1071") 
if(!require("topicmodels")) install.packages("topicmodels") 
if(!require("caret")) install.packages("caret") 
if(!require("stopwords")) install.packages("stopwords")
if(!require("naivebayes")) install.packages("naivebayes")
if(!require("ggplot2")) install.packages("ggplot2") 

```

*  **Chargement des packages nécessaires :**

```{r}

library(dplyr)
library(kableExtra)
library(tm)
library(MASS)
library(e1071)
library(topicmodels)
library(caret)
library(stopwords)
library(naivebayes)
library(stopwords)
library(ggplot2)

```

*  **Première étape :**

```{r}
file.remove("THESE_DATASET.Rda")
file.remove("THESE_CLEAN.Rda")

rm(list = ls())

```

*  **Seconde étape :**

```{r}
# Update this path to match your actual file location
csv_file <- "french_thesis_20231021_metadata.csv"
df_temp <- read.csv(csv_file)
save(df_temp, file = "THESE_DATASET.Rda")

```

*  **Troisième étape :**

```{r}

rm(df_temp)
rm(list = ls())
load("THESE_DATASET.Rda")
colnames(df_temp)
head(df_temp)

```

*  **Vérification du nombre de descriptions vides  :**

```{r}

nb_vide <- sum(df_temp$Description == "")
nb_na <- sum(is.na(df_temp$Description))

total_lignes <- nrow(df_temp)
total_inutiles <- nb_vide + nb_na

cat("Nombre total de lignes :", total_lignes, "\n")
cat("--- \n")
cat("Total à supprimer :", total_inutiles, "\n")

```


*  **Quatrième étape :**

```{r}

df_clean <- df_temp %>%
  dplyr::rename(Subject = Domain, 
                Texte = Description) %>% 
  dplyr::select(Subject, Texte)

#On va enlever les lignes vides car il y a quelques descriptions vides

df_clean <- df_clean %>% 
  filter(!is.na(Texte) & Texte != "" & Texte != " ")

cat("Nombre de lignes après le nettoyage : ", nrow(df_clean), "\n")

set.seed(123)
df_clean <- df_clean %>%
            sample_n(5000)  # Réduire à 5000 pour une exécution plus rapide

kable(head(df_clean), caption = "Jeu de données") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "center")%>%  
  scroll_box( height = "200px")

```

*  **Regroupement des thèmes en catégories principales :**

```{r}

# Créer une fonction pour regrouper les thèmes similaires
regroup_subjects <- function(subject) {
  subject <- tolower(subject)
  
  # Ordre d'importance : être plus spécifique d'abord
  if (grepl("biologie|écologie|environnement|biodiversité|organisme|cellulaire|moléculaire|terre|géologie|océan|espace|atmosphère|climat|toxicologie|médecine|pharmacologie|neurosciences|oncologie|épidémiologie|cancérologie", subject)) {
    return("Biologie et Sciences de la Vie")
  } else if (grepl("chimie|physique|matériaux|minérale|organique|analytique|énergétique", subject)) {
    return("Chimie et Physique")
  } else if (grepl("informatique|numérique|signal|communication|télécommunication|électronique", subject)) {
    return("Informatique et Télécommunications")
  } else if (grepl("génie|ingénieur|technologie|civil|mécanique|électrique|énergie|fluide|dynamique", subject)) {
    return("Génie et Technologie")
  } else if (grepl("droit|juridique|science.*politique|politique|gouvernement|constitution|public|privé|international|criminel", subject)) {
    return("Droit et Sciences Politiques")
  } else if (grepl("mathématique|statistique|probabilité", subject)) {
    return("Mathématiques et Statistiques")
  } else if (grepl("histoire|archéologie|littérature|langue|étude|germaniques|anglaises|italienne|latino|nord-américain|cinéma", subject)) {
    return("Histoire et Lettres")
  } else if (grepl("anthropologie|sociologie|psychologie|sciences.*humaines|ethnologie|sport|mouvement|éducation|formation|pédagogie|apprentissage|enseignement", subject)) {
    return("Sciences Humaines et Sociales")
  } else {
    # Si on arrive ici, on essaie de capturer des éléments génériques
    if (grepl("science", subject)) {
      return("Sciences générales")
    }
    return("Sciences générales")  # Plutôt que "Autres"
  }
}

# Appliquer le regroupement
df_clean$Subject <- sapply(df_clean$Subject, regroup_subjects)

# Afficher la nouvelle distribution
table_subjects <- table(df_clean$Subject)
cat("\nDistribution des catégories :\n")
print(table_subjects)

# Garder seulement les catégories avec au moins 50 documents
df_clean <- df_clean %>%
  filter(Subject %in% names(table_subjects)[table_subjects >= 50])

cat("\nNombre total après filtrage :", nrow(df_clean), "\n")
cat("Nombre de catégories :", length(unique(df_clean$Subject)), "\n")
cat("\nDistribution finale :\n")
print(table(df_clean$Subject))

```

*  **Cinquième étape :**

```{r}

#On va maintenant enregistrer le nouveau dataframe et on nettoie 

save(df_clean, file = "THESE_CLEAN.Rda")
rm(df_clean, df_temp)
file.remove("THESE_DATASET.Rda")

```

*  **Sixième étape :**

```{r}

#On charge le nouveau jeu de données 
rm(list = ls())
load("THESE_CLEAN.Rda")
colnames(df_clean)

```

*  **Septième étape :**

```{r}

#Présentation des données finales 

kable(head(df_clean), caption = "Jeu de données") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "center")%>%  
  scroll_box( height = "200px")

```


#### <FONT color='#0066CC'><FONT size = 3> 2.2 Préparation pour l'AFD et le Bayésien (NLP) </FONT></FONT>

<DIV align = justify>

Maintenant on va passer au traitement du texte. L'objectif va être de transformer les résumés en données numériques. Contrairement au mini projet 2 (Twitter), nous devions
traiter de l'anglais, ici nous allons devoir traiter du français donc il va falloir gérer les accents et des mots vides différents. 


```{r}

# Charger les stopwords français
suppressWarnings({
  stopwords_fr <- stopwords::stopwords("fr")
})

# Créer un corpus à partir des textes
corpus <- Corpus(VectorSource(df_clean$Texte))

# Nettoyage du texte
corpus <- corpus %>%
  tm_map(content_transformer(tolower)) %>%           # Convertir en minuscules
  tm_map(content_transformer(function(x) iconv(x, from = "UTF-8", to = "ASCII//TRANSLIT"))) %>%  # Supprimer les accents
  tm_map(removePunctuation) %>%                       # Supprimer la ponctuation
  tm_map(removeNumbers) %>%                           # Supprimer les chiffres
  tm_map(stripWhitespace) %>%                         # Supprimer les espaces superflus
  tm_map(removeWords, stopwords_fr)                   # Supprimer les stopwords français

# Créer une matrice document-terme (DTM)
dtm <- DocumentTermMatrix(corpus)

# Supprimer les termes très rares (qui apparaissent dans moins de 0.1% des documents)
sparse_threshold <- 0.999
dtm_reduced <- removeSparseTerms(dtm, sparse_threshold)

# Convertir en matrice dense pour les analyses
data_matrix <- as.matrix(dtm_reduced)

cat("Dimensions de la matrice document-terme :", nrow(data_matrix), "x", ncol(data_matrix), "\n")

```

*  **Vectorisation TF-IDF :**

```{r}

# Créer une matrice TF-IDF
tfidf_matrix <- weightTfIdf(dtm_reduced)
tfidf_data <- as.matrix(tfidf_matrix)

cat("Dimensions de la matrice TF-IDF :", nrow(tfidf_data), "x", ncol(tfidf_data), "\n")
cat("Nombre de termes uniques :", ncol(tfidf_data), "\n")

```

*  **Sélection des termes les plus importants :**

```{r}

# Calculer la variance de chaque terme et sélectionner les tops 
variances <- apply(tfidf_data, 2, var)
top_indices <- order(variances, decreasing = TRUE)[1:min(200, length(variances))]
tfidf_data_reduced <- tfidf_data[, top_indices]

cat("Dimensions après réduction :", nrow(tfidf_data_reduced), "x", ncol(tfidf_data_reduced), "\n")

```

*  **Combinaison avec la variable cible :**

```{r}

# Créer un dataframe avec les données TF-IDF réduites et la variable cible
df_features <- data.frame(
  Subject = df_clean$Subject,
  as.data.frame(tfidf_data_reduced)
)

# Afficher les dimensions
cat("Dimensions du dataset avec features TF-IDF :", nrow(df_features), "x", ncol(df_features), "\n")

# Afficher la distribution des classes
table_dist <- table(df_features$Subject)
cat("\nDistribution des classes :\n")
print(table_dist)

```

#### <FONT color='#0066CC'><FONT size = 3> 2.3 Analyse Factorielle Discriminante (AFD) </FONT></FONT>

<DIV align = justify>

L'Analyse Factorielle Discriminante est une technique de réduction de dimensionnalité supervisée qui cherche à maximiser la séparation entre les classes. Elle crée de nouvelles variables (axes discriminants) qui sont les meilleures combinaisons linéaires des variables originales pour distinguer les différentes classes.

```{r}

# Sélectionner uniquement les variables numériques (termes TF-IDF)
X <- df_features[, -1]
y <- df_features$Subject

# Appliquer l'AFD
lda_model <- MASS::lda(X, grouping = y)

# Afficher les informations du modèle
cat("Nombre d'axes discriminants :", length(lda_model$svd), "\n")
cat("Proportions de la variance expliquée :\n")
print(lda_model$svd^2 / sum(lda_model$svd^2))

# Obtenir les scores des axes discriminants
lda_scores <- predict(lda_model, X)$x

# Créer un dataframe avec les scores et la classe
df_lda <- data.frame(
  Subject = y,
  lda_scores
)

cat("Dimensions des données après AFD :", nrow(df_lda), "x", ncol(df_lda), "\n")

# Créer un tableau récapitulatif des résultats de l'AFD avec tests de Wilks
n_axes <- min(2, length(lda_model$svd))  # Prendre max 2 axes pour le tableau
result_afd <- matrix(0, nrow = n_axes, ncol = 6)

# Valeurs propres
result_afd[, 1] <- lda_model$svd[1:n_axes]^2

# Pourcentage d'inertie
result_afd[, 2] <- (lda_model$svd[1:n_axes]^2 / sum(lda_model$svd^2)) * 100

# Corrélations canoniques
result_afd[, 3] <- sqrt(lda_model$svd[1:n_axes]^2 / (1 + lda_model$svd[1:n_axes]^2))

# Wilks Lambda 
result_afd[, 4] <- cumprod(1 - result_afd[, 3]^2)

# Khi-deux
N <- nrow(X)
P <- ncol(X)
K <- length(unique(y))
result_afd[, 5] <- -(N - (P + K)/2 - 1) * log(result_afd[, 4])

# p-value
result_afd[, 6] <- 1 - pchisq(result_afd[, 5], P * (K - 1))

result_afd_df <- data.frame(result_afd)
colnames(result_afd_df) <- c("Valeur propre", "% Inertie", "Corrélation", "Wilks Lambda", "Khi-deux", "p-value")
rownames(result_afd_df) <- paste0("Axe ", 1:n_axes)

kable(result_afd_df, caption = "Tests de Wilks") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "center")%>%  
  scroll_box( height = "200px")
```

*  **Visualisation avec ggplot2 (centres de gravité) :**

```{r fig.width=14, fig.height=8}

# Créer un dataframe pour ggplot2
plot_data_gg <- data.frame(
  LD1 = lda_scores[, 1],
  LD2 = lda_scores[, 2],
  Class = y
)

# Calculer les centres de gravité de chaque classe
centers <- aggregate(cbind(LD1, LD2) ~ Class, data = plot_data_gg, mean)

# Créer le graphique avec ggplot2
ggplot(plot_data_gg, aes(x = LD1, y = LD2, colour = Class)) +
  geom_point(size = 2, alpha = 0.6) +
  geom_point(data = centers, aes(x = LD1, y = LD2, colour = Class), 
             shape = 23, size = 5, fill = "red") +  # Centres en losange rouge
  geom_hline(yintercept = 0, size = 0.1, colour = 'black', linetype = "dashed") +
  geom_vline(xintercept = 0, size = 0.1, colour = 'black', linetype = "dashed") +
  theme_minimal() +
  ggtitle("Projection AFD avec centres de gravité") +
  xlab("Axe discriminant 1") +
  ylab("Axe discriminant 2") +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 10),
    legend.title = element_text(size = 11),
    plot.title = element_text(size = 13, hjust = 0.5),
    axis.title = element_text(size = 11)
  ) +
  guides(colour = guide_legend(ncol = 1, override.aes = list(size = 3)))

```

</DIV>

<hr style="border: 1px solid gray">

</hr>

### <FONT color='#0066CC'><FONT size = 4> 3. Classification Bayésienne Naïve </FONT></FONT>

<DIV align = justify>
Nous passons maintenant à l'une des dernières étapes, l'objectif est de prédire la discipline de la thèse en utilisant les informations condensées par l'AFD. 

Pour cela, nous allons utiliser les scores factoriels (colonnes contenues dans notre tableau df_lda).
Nous allons appliquer le théorème de Bayes sur les composantes de l'AFD. L'utilisation des axes de l'AFD est idéale car ils sont orthogonaux, ce qui respecte l'hypothèse d'indépendance du classifieur Bayésien Naïf. 

Pour évaluer notre modèle nous n'allons pas juste faire le découpage habituel apprentissage / Test, nous allons utiliser la validation croisée. Cela veut donc dire qu'on va découper nos données en 10 parts égales.
La machine va ensuite entrainer le modèle sur 9 parts et le tester sur la dernière et elle va répéter l'opération 10 fois en changeant la part de test pour chaque tour. 
Cela va permettre d'avoir une estimation beaucoup plus fiable du modèle. 


```{r}

df_lda$Subject <- as.factor(df_lda$Subject)

# On renomme les catégories pour éviter les erreurs 
levels(df_lda$Subject) <- make.names(levels(df_lda$Subject))

set.seed(123)
train_control <- trainControl(
  method = "cv",
  number = 10,
  savePredictions = "final",
  classProbs = TRUE
)

model_cv <- train(
  Subject ~ ., 
  data = df_lda,
  method = "naive_bayes",
  trControl = train_control
)

print(model_cv)

```

#### <FONT color='#0066CC'><FONT size = 3> 3.1 Évaluation des performances </FONT></FONT>

Une fois que le modèle a été entrainé sur les 10 blocs nous allons maintenant regarder la moyenne des résultats. 
L' accuracy va nous permettre de nous indiquer quel est le pourcentage de thèses qui sont correctement classées parmi toutes les disciplines. 
Le Kappa est une mesure qui va prendre en compte le hasard. 

```{r}

cv_accuracy <- max(model_cv$results$Accuracy)
cv_kappa <- model_cv$results$Kappa[which.max(model_cv$results$Accuracy)]

metrics <- data.frame(
  Mesure = c("Accuracy", "Kappa (CV 10-fold)", "Nombre de classes"),
  Valeur = c(
    paste0(round(cv_accuracy * 100, 2), " %"),
    round(cv_kappa, 3),
    length(levels(df_lda$Subject))
  )
)

kable(metrics, caption = "Performance du Modèle Bayésien (Validation Croisée)") %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "center")

```

On obtient une précision de presque 50 % cela peut sembler moyen au départ mais il faut se rappeler qu'on a 9 classes possibles.
Cela signifie que si on réalise un tirage au sort aléatoire on aurait environ 11% de résuitte donc notre modèle est quand même 
presque 5 fois plus performant que le hasard. 


Pour essayer de comprendre où notre modèle réussit et où il se trompe, nous construisons la matrice de confusion. 

```{r}

cv_predictions <- model_cv$pred

final_preds <- cv_predictions[cv_predictions$Resample != "Resample", ]

cm_cv <- confusionMatrix(final_preds$pred, final_preds$obs)


kable(cm_cv$table, caption = "Matrice de Confusion (Validation Croisée)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "center") %>%
  scroll_box(height = "400px")

```

Pour pouvoir mieux comprendre ce que nous obtenons, nous allons calculer le taux de réussite pour chaque matière.

*  **Performance par classe :**

```{r}

# Créer une table de performance par classe
class_performance <- data.frame(
  Classe = rownames(cm_cv$table),
  Prédictions_Correctes = diag(cm_cv$table),
  Total = rowSums(cm_cv$table)
)
class_performance$Taux_Reussite <- round(class_performance$Prédictions_Correctes / class_performance$Total * 100, 2)

# Retirer le préfixe technique (points) pour un affichage plus lisible
class_performance$Classe <- gsub("\\.", " ", class_performance$Classe)

kable(class_performance, caption = "Taux de réussite par classe") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "center")

```

On visualise ensuite ces résultats graphiquement afin de mieux comparer chaque disciplines : 

*  **Graphique de précision par catégorie :**

```{r fig.width=12, fig.height=6}

# Créer un graphique de précision par catégorie
accuracy_by_class <- data.frame(
  Class = class_performance$Classe,
  Accuracy = class_performance$Taux_Reussite
)

# Trier par précision
accuracy_by_class <- accuracy_by_class[order(accuracy_by_class$Accuracy), ]
accuracy_by_class$Class <- factor(accuracy_by_class$Class, 
                                   levels = accuracy_by_class$Class)

# Créer le graphique
ggplot(accuracy_by_class, aes(x = Class, y = Accuracy, fill = Accuracy)) +
  geom_bar(stat = "identity", color = "black", size = 0.5) +
  scale_fill_gradient(low = "red", high = "green", limits = c(0, 100)) +
  geom_hline(yintercept = mean(accuracy_by_class$Accuracy), 
             linetype = "dashed", color = "blue", size = 0.7) +
  coord_flip() +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 13, hjust = 0.5, face = "bold"),
    legend.position = "right"
  ) +
  ggtitle("Précision de classification par catégorie") +
  xlab("Catégorie") +
  ylab("Précision (%)") +
  ylim(0, 100)

```

*  **Résumé des résultats :**

```{r}

cat("Nombre total de thèses traitées :", nrow(df_lda), "\n")
cat("Nombre de catégories :", length(unique(df_lda$Subject)), "\n")
cat("Nombre de features TF-IDF :", ncol(X), "\n")
cat("Nombre d'axes discriminants utilisés pour le Bayésien :", ncol(df_lda) - 1, "\n\n")

cat("Accuracy globale :", round(cv_accuracy * 100, 2), "%\n")
cat("Kappa :", round(cv_kappa, 3), "\n\n")

# Calculer les meilleures et pires catégories
best_idx <- which.max(class_performance$Taux_Reussite)
worst_idx <- which.min(class_performance$Taux_Reussite)

cat("Meilleure catégorie :", class_performance$Classe[best_idx], 
    " (", class_performance$Taux_Reussite[best_idx], "%)\n")
cat("Catégorie la plus difficile :", class_performance$Classe[worst_idx], 
    " (", class_performance$Taux_Reussite[worst_idx], "%)\n\n")

cat("Nombre moyen de thèses par catégorie :", round(mean(class_performance$Total), 1), "\n")

```

Ce que l'on peut conclure de ces résultats, c'est que par exemple les disciplines comme le "Droit et Sciences Politiques" ou encore l'Histoire ont une meilleure précision que les autres disciplines,
surement car ce sont des disciplines qui utilisent un vocabulaire très spécifiques comme par exemple "lois, siècles, époques etc...".

Les autres disciplines un peu plus scientifique sont un peu plus compliquée à prédire car les mots se ressemblent, c'est à la fois des mathématiques ou de la physique ce qui complique les choses pour le modèle. 

</DIV>

<hr style="border: 1px solid gray">

</hr>

<DIV align = justify>

### <FONT color='#0066CC'><FONT size = 4> 4. Conclusion </FONT></FONT>

Ce projet nous a donc permis d'utiliser différentes méthodes de traitement de textes pour résoudre un problème : classer automatiquement des thèses de doctorat par discipline. 

Pour cela nous avons suivi trois grandes étapes. 

Tout d'abord nous avons traité les textes en les nettoyant et en utilisant la métjode de TF-IDF afin de transformer les mots en valeur numériques. 

Ensuite nous avons utillisé l'AFD. Cette méthode a permis de réduire le nombre de variables tout en séparant du mieux possible les différentes disciplines. 

Et enfin, nous avons appliqué un classifieur Bayésien naïf en utilisant les axes fournis par l'AFD afin de prédire au mieux chaque thèse. 

Nous avons ensuite réalisée une validation croisée, et on a obtenu une précision d'environ 50%. Ce résultat est satisfaisant contenu de la difficulté du problème (9 disciplines proches les unes des autres). 

Grâce à ce projet on a pu comprendre comment allier les méthodes de réduction de dimension et la classification afin de créer un modèle performant. 

</DIV>