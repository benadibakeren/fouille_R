---
title: "Projet 1 – Classification bayésienne des émotions"
author: "Benadiba Keren  & Zerroug Méliana "
output:
  html_document:
    toc: true
---

# I- Introduction

Ce projet s’inscrit dans le cadre du module **AP-4209 – Statistique bayésienne** et a pour
objectif principal la mise en œuvre d’un **classificateur bayésien naïf** destiné à la
prédiction des émotions à partir de textes en langage naturel.

Le jeu de données utilisé provient de la plateforme Kaggle et se compose de phrases
correspondant à différentes catégories émotionnelles comme la colère ou la peur.
Avant de traiter ces données, il est nécessaire d'effectuer un ensemble d’étapes de prétraitement 
afin de réduire le bruit et d’extraire les informations pertinentes. Ces étapes incluent notamment le
nettoyage du texte, la tokenization, le stemming ou la lemmatization, ainsi que la
vectorisation des données.

L’étude a pour but de mettre en évidence
les forces et les limites de l’approche bayésienne 
dans notre contexte: la classification d’émotions.

# II- Méthodologie

Afin de préparer les données textuelles pour la modélisation, plusieurs étapes de
prétraitement doivent être appliquées. Ces étapes visent à réduire le bruit du texte tout en
conservant les informations les plus importantes. Le prétraitement est composé de plusieurs étapes. On commence par normaliser les données en mettant
tout le texte en minuscule. Ensuite, nous supprimons les données inutiles telles que la ponctuation, les chiffres et les mots vides.
Nous finirons par appliquer la tokenization et le stemming. Ces transformations permettent
d’améliorer la qualité de la représentation vectorielle utilisée par le classificateur
bayésien.

**Interprétation**:
L'analyse de la distribution des classes permet d’identifier un possible déséquilibre entre les classes d’émotions,
ce qui pourrait influencer les performances du modèle de manière négative. 

Après le prétraitement, les documents textuels sont transformés en une représentation 
numérique à l’aide de la méthode TF-IDF. Cette méthode permet d'observer l’importance 
des mots en fonction de leur fréquence dans un document et de leur rareté dans l’ensemble 
du corpus.
Pour améliorer la capacité du modèle à capturer le contexte émotionnel, nous utilisons 
des **bi-grammes** en plus des mots individuels. Un bi-gramme est une séquence de deux 
mots consécutifs (par exemple "not happy", "very sad"). Cette approche permet au modèle 
de mieux comprendre les nuances de sentiment que des mots isolés ne pourraient pas capturer.
Les données sont divisées en un ensemble d’apprentissage et un ensemble de test dans le
but d’évaluer les performances du modèle sur des données non vues lors de l’entraînement.

Le modèle que nous allons utiliser est un **classificateur bayésien naïf**.

*  **Installation des packages nécessaires :**  

```{r}

if(!require("dplyr")) install.packages("dplyr")
if(!require("kableExtra")) install.packages("kableExtra")
if(!require("tm")) install.packages("tm")
if(!require("MASS")) install.packages("MASS") 
if(!require("e1071")) install.packages("e1071")
if(!require("SnowballC")) install.packages("SnowballC")

```


*  **Chargement des packages nécessaires :**

```{r}

library(e1071)
library(caret)
library(tm) #texte brut en texte numérique
library(SnowballC) #stemming

```

## Chargement des données

```{r}
data <- read.csv("Emotion_classify_Data.csv", stringsAsFactors = FALSE)
data <- data[!is.na(data$Comment) & !is.na(data$Emotion), ]
data$Comment <- trimws(data$Comment)
kable(head(data,100), caption = "Extrait du jeu de données") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "center") %>%
  scroll_box(height = "300px", width = "100%")
str(data)
```

## Analyse des données

```{r}
table(data$Emotion)
barplot(table(data$Emotion),
main = "Distribution des émotions",
col = "steelblue",
las = 2)
```

## Longueur de texte 

```{r}

names(data)
data$text_length <- nchar(as.character(data$Comment))
summary(data$text_length)
hist(data$text_length,
breaks = 30,
col = "lightblue",
main = "Distribution de la longueur des textes",
xlab = "Nombre de caractères")
```


```{r}

# Création du corpus
corpus <- VCorpus(VectorSource(data$Comment))

# Prétraitement
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)

stop_words <- stopwords("en")
negations <- c("not", "no", "never", "n't")
stop_words_clean <- setdiff(stop_words, negations)

corpus <- tm_map(corpus, removeWords, stop_words_clean)
corpus <- tm_map(corpus, stemDocument, language = "en")

corpus
```


```{r}
# Création d'un tokenizer pour capturer les mots seuls ET les bi-grammes (sans RWeka)
BigramTokenizer <- function(x) {
  words_list <- unlist(strsplit(as.character(x), " +"))
  # Unigrammes (mots seuls)
  unigrams <- words_list
  # Bigrammes (paires de mots consécutifs)
  bigrams <- if(length(words_list) > 1) {
    sapply(1:(length(words_list)-1), function(i) paste(words_list[i], words_list[i+1]))
  } else character(0)
  # Combinaison des deux
  c(unigrams, bigrams)
}

dtm <- DocumentTermMatrix(
  corpus,
  control = list(
    tokenize = BigramTokenizer,
    weighting = weightTfIdf,
    bounds = list(global = c(5, Inf)),
    wordLengths = c(2, Inf)
  )
)

dtm <- removeSparseTerms(dtm, 0.99)

dtm
```

```{r}
set.seed(123)

train_index <- createDataPartition(data$Emotion, p = 0.8, list = FALSE)

dtm_train <- dtm[train_index, ]
dtm_test  <- dtm[-train_index, ]

label_train <- data$Emotion[train_index]
label_test  <- data$Emotion[-train_index]
```

---

---


```{r}

model_nb <- naiveBayes(
  as.matrix(dtm_train),
  as.factor(label_train),
  laplace = 1
)

predictions <- predict(
  model_nb,
  as.matrix(dtm_test)
)

```

# Résultats

```{r}
conf_matrix <- confusionMatrix(
  as.factor(predictions),
  as.factor(label_test),
  mode = "everything"
)

conf_matrix
```


```{r}
#Indicateurs de performance
conf_matrix$overall[c("Accuracy", "Kappa")]
conf_matrix$byClass[, c("F1", "Sensitivity", "Specificity", "Balanced Accuracy")]
```

# Validation croisée 

Afin de vérifier plus concrètement l'efficacité de notre modèle nous allons appliquer une validation croisée 

```{r}

dtm_kfold_mat <- as.matrix(removeSparseTerms(dtm, 0.995))
labels_kfold <- as.factor(data$Emotion)

train_control <- trainControl(method = "cv", number = 10)

set.seed(123)
model_kfold <- train(
  x = dtm_kfold_mat, 
  y = labels_kfold,
  method = "naive_bayes",
  trControl = train_control,
  tuneGrid = expand.grid(laplace = 1, usekernel = FALSE, adjust = 1)
)

print(model_kfold)

```




# III- Résultats

**Interprétation**:

La matrice de confusion nous permet d'analyser les performances du classificateur bayésien naïf.

L’émotion **anger** obtient une sensibilité de 0.33, cela signifie qu'environ seulement un tiers des messages de colère est correctement identifié.
Cependant la spécificité est de 0.84 ce qui indique que le modèle est trop prudent et fait très peu de faux positifs.
La balanced accuracy est de 0.58 cela montre une performance plutôt moyenne.  

L’émotion **fear** est beaucoup plus compliqué à détecter pour notre modèle, on a une sensibilité très faible de 0.15.
La grande majorité des expressions de peurs sont classées dans la joie. Cependant, elle possède la spécificité la plus élevée 0.96 cela signifie que lorsque le modèle prédit "fear" il a de fortes chances d'avoir raison. 

L’émotion **joy** a la sensibilité la plus élevée (0.89) cela signifie que le modèle arrive à trouver tous les textes de joie.
Cependant sa spécificité est très faible (0.38). Il y a donc un fort biais le modèle prédit pratiquement que de la joie. Malgré cela la joie obtient quand même la meilleure balanced accuracy (0.63) du modèle 

La validation croisée (avec 10 plis) nous donne une précision d'environ 45.21%, ce résultat reste très proche du résultat que nous avions trouvé précédemment.
Cela nous montre que les performances de notre modèle sont stables. Notre modèle permet donc de montrer la réelle capacité du classificateur Naive Bayes 
à pouvoir traiter ce jeu de données avec les prétraitements que nous avons choisi. 

De plus, de manière globale, les résultats montrent une amélioration de la détection des émotions par rapport 
aux premières versions du modèle. Cela est dû à l’introduction d’un prétraitement plus stricte, notamment avec la conservation 
des termes de négation. Le coefficient Kappa de 0.18 permet de souligner le fait que l'accord entre les prédictions et la réalité reste très faible.
Tous ces résultats permettent de montrer la difficulté pour un modèle bayésien naïf de pouvoir distinguer correctement les émotions surtout quand ici la joie à l'air de dominer le processus de décision 

# IV- Discussion

Les résultats obtenus montrent que le classificateur bayésien naïf, combiné à la représentation 
TF-IDF, est capable d’identifier certaines émotions à partir des textes, mais avec différentes performances selon les classes. 
L’analyse effectuée précédemment montre que ce modèle a développé une forte capacité à identifier l'émotion joy au détriment des émotions fear et anger.
Ces différences s’expliquent par le vocabulaire varié utilisé dans les textes.

Le classificateur bayésien naïf repose sur une hypothèse d’indépendance entre les mots 
qui ne permet pas de modéliser des textes avec du vocabulaire trop complexe. De plus, même si les classes sont équilibrées en nombre,
le déséquilibre du au mots (certains mots peuvent être plus prédictifs pour une classe que pour une autre) impacte les résultats. 

Ces observations montrent que des méthodes simples peuvent fournir des résultats corrects et facilement
interprétables, tout en révélant rapidement leurs limites lorsque les données deviennent plus complexes, 
comme c’est le cas pour la classification d’émotions à partir de textes.

# V- Conclusion et perspectives

Ce projet a permis de mettre en place une méthode complète de classification
d’émotions à partir de données textuelles en utilisant une approche bayésienne. Le
classificateur bayésien naïf s’est montré efficace tout en restant simple à mettre en
œuvre et facile à interpréter.

Pour améliorer les performances du modèle, plusieurs options peuvent être envisagées.
Nous pourrions favoriser l’utilisation de groupes de mots plutôt que de mots isolés. Il serait
également intéressant d'avoir une meilleure prise en compte du déséquilibre entre les classes.